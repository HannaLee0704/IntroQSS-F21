<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Regression basics</title>
    <meta charset="utf-8" />
    <link href="slides_51_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="slides_51_files/remark-css-0.0.1/robot.css" rel="stylesheet" />
    <link href="slides_51_files/remark-css-0.0.1/robot-fonts.css" rel="stylesheet" />
    <script src="slides_51_files/kePrint-0.0.1/kePrint.js"></script>
    <link href="slides_51_files/lightable-0.0.1/lightable.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Regression basics
## PLSC30500, Fall 2021

---





class: inverse, middle, center

# What is regression? 


&lt;!-- Todo: might add a thing about interpreting the coefficient by plotting it via predictions, etc -- what IS the best way to do that, anyway? might be sjplot plot_model  --&gt;

---

## Regression in general 

In **regression analysis**, we estimate the relationship between a **dependent variable** `\((Y_i)\)` and **independent variables** `\((X_i, D_i, \ldots)\)`

&lt;br&gt; &lt;/br&gt;

Regression **describes** the relationship between `\(Y_i\)` and `\(\mathbf{X}_i\)`, but in some circumstances we can use it for  

- prediction (what will `\(Y_i\)` be, given some `\(X_i\)`?)
- causal inference (what is effect of `\(D_i\)` on `\(Y_i\)`?)

---

## Prediction and causal inference: an example

Suppose we had this data for each country `\(i\)`:

- `\(Y_i\)`: was there civil conflict?
- `\(D_i\)`: was there a peace-keeping operation in the past 5 years? 
- `\(X_i\)`: GDP

--

&lt;br&gt; &lt;/br&gt;

Would `\(D_i\)` and `\(X_i\)` be useful **predictors** of `\(Y_i\)`? 

If `\(D_i\)` predicts `\(Y_i\)`, does that mean peace-keeping affects civil conflict?

---

## Ordinary least squares regression

When we say "regression" we often mean **ordinary least squares (OLS)**.

--

We seek a linear prediction of `\(Y\)` based on `\(D_i\)` and `\(X_i\)`: 

$$ \hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 D_i + \hat{\beta}_2 X_i $$ 
--

Define `\(Y_i - \hat{Y_i} = \hat{r}_i\)` as the **residual**. 

--

We seek **coefficients** `\(\hat{\beta}_0, \hat{\beta}_1, \hat{\beta}_2\)` that minimize the **sum of squared residuals**, i.e.

$$ \underset{\hat{\beta}_0, \hat{\beta}_1, \hat{\beta}_2}{\arg\min} \sum_i  \left(Y_i - (\hat{\beta}_0 + \hat{\beta}_1 D_i + \hat{\beta}_2 X_i)\right)^2 $$


---

## Toy example 


.pull-left[

Suppose we have this data: 
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; x &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; y &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.16 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; -1.46 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.86 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1.04 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.59 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

.pull-right[
&lt;img src="slides_51_files/figure-html/unnamed-chunk-1-1.png" width="500px" style="display: block; margin: auto;" /&gt;
]

&lt;br&gt; &lt;/br&gt;
&lt;br&gt; &lt;/br&gt;

What slope `\(\hat{\beta}_0\)` and intercept `\(\hat{\beta}_1\)` would minimize the sum of squared residuals? 

---

## Regression through guessing 

Let's try `\(\hat{\beta}_0 = 0\)` and `\(\hat{\beta}_1 = 1\)`.

&lt;img src="slides_51_files/figure-html/unnamed-chunk-2-1.png" width="600px" style="display: block; margin: auto;" /&gt;

What is the sum of squared residuals? 

---

## Computing SSR 


```r
# dplyr way
df %&gt;% 
  mutate(prediction = 0 + 1*x,
         residual = y - prediction) %&gt;% 
  summarize(ssr = sum(residual^2))
```

```
## # A tibble: 1 x 1
##     ssr
##   &lt;dbl&gt;
## 1 0.813
```

```r
# more concise way 
df %&gt;% 
  summarize(ssr = (y - x)^2 %&gt;% sum())
```

```
## # A tibble: 1 x 1
##     ssr
##   &lt;dbl&gt;
## 1 0.813
```

```r
# base R way
sum((df$y - df$x)^2)
```

```
## [1] 0.8127729
```

---

## A function 


```r
ssr_for_df &lt;- function(intercept, slope){
  df %&gt;% 
*   mutate(prediction = intercept + slope*x,
           residual = y - prediction) %&gt;% 
    summarize(ssr = sum(residual^2)) %&gt;% 
    as.numeric()
}
```

For example: 


```r
ssr_for_df(intercept = 0, slope = 1)
```

```
## [1] 0.8127729
```

```r
ssr_for_df(intercept = 0, slope = 2)
```

```
## [1] 2.33613
```

---

## "Grid search" over one dimension

We compute SSR for a range of slopes assuming intercept of zero: 


```r
tibble(intercept = 0, slope = seq(0, 2, by = .05)) %&gt;% 
  mutate(ssr = map2_dbl(intercept, slope, ssr_for_df)) %&gt;% 
  ggplot(aes(x = slope, y = ssr)) + 
  geom_point()
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-6-1.png" width="900px" style="display: block; margin: auto;" /&gt;

---

## "Grid search" over two dimensions

Now consider other intercepts: 


```r
expand_grid(intercept = seq(-.25, .25, by = .05), slope = seq(1, 1.5, by = .05)) %&gt;% 
  mutate(ssr = map2_dbl(intercept, slope, ssr_for_df)) %&gt;% 
  ggplot(aes(x = intercept, y = slope, fill = ssr)) + 
  geom_tile() + 
  coord_fixed()
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-7-1.png" width="900px" style="display: block; margin: auto;" /&gt;

---

## There must be a better way

Grid search works, but `\(\ldots\)`.

`R` has better ways: 


```r
lm(y ~ x, data = df)
```

```
## 
## Call:
## lm(formula = y ~ x, data = df)
## 
## Coefficients:
## (Intercept)            x  
##     -0.1444       1.2740
```

```r
estimatr::lm_robust(y ~ x, data = df)
```

```
##               Estimate Std. Error    t value  Pr(&gt;|t|)  CI Lower CI Upper DF
## (Intercept) -0.1443664  0.4071450 -0.3545822 0.7830711 -5.317634 5.028901  1
## x            1.2739734  0.3841524  3.3163225 0.1864455 -3.607146 6.155093  1
```

---

## How? 

Calculus and linear algebra. (See Linear Models, next course in sequence!)

---

## It's just "linear" regression, right?

In OLS we model `\(Y\)` as an additive function of predictors: 

`$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \ldots + \beta_k X_{ik} + \epsilon_i$$`

--

.pull-left[
Does this mean OLS is only useful when you have relationships that look like this?

**No.**
]


.pull-right[
&lt;img src="slides_51_files/figure-html/unnamed-chunk-9-1.png" width="400px" style="display: block; margin: auto;" /&gt;

]


---

Here we put in:

- transformations (logs, polynomials)
- categorical variables 

---


We can handle non-linear relationships by **transforming** variables. 


```r
mtcars %&gt;%
  ggplot(aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = lm, formula = y ~ x, se = F)
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-10-1.png" width="900px" style="display: block; margin: auto;" /&gt;

```r
mtcars %&gt;%
  mutate(log_wt = log(wt)) %&gt;% 
  ggplot(aes(x = log_wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = lm, formula = y ~ x, se = F)
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-10-2.png" width="900px" style="display: block; margin: auto;" /&gt;

```r
mtcars %&gt;%
  mutate(log_mpg = log(mpg)) %&gt;% 
  ggplot(aes(x = wt, y = log_mpg)) + 
  geom_point() + 
  geom_smooth(method = lm, formula = y ~ x, se = F)
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-10-3.png" width="900px" style="display: block; margin: auto;" /&gt;


with You can use many predictors as you want. 

They can be distinct predictors


```r
lm(mpg ~ wt + disp + hp + qsec, data = mtcars)
```

```
## 
## Call:
## lm(formula = mpg ~ wt + disp + hp + qsec, data = mtcars)
## 
## Coefficients:
## (Intercept)           wt         disp           hp         qsec  
##   27.329638    -4.609123     0.002666    -0.018666     0.544160
```

or **transformations** of the same predictor 



```r
wt_seq &lt;- tibble(wt = seq(min(mtcars$wt), max(mtcars$wt), by = .01))
  
wt_seq %&gt;%
  mutate(mpg = predict(lm(mpg ~ wt, data = mtcars), newdata = .)) -&gt; mtcars_wt

mtcars %&gt;% 
  ggplot(aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_line(data = mtcars_wt, col = "blue")
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-12-1.png" width="900px" style="display: block; margin: auto;" /&gt;


---


```r
wt_seq %&gt;%
  mutate(mpg = predict(lm(mpg ~ wt + I(wt^2), data = mtcars), newdata = .)) -&gt; mtcars_wt

mtcars %&gt;% 
  ggplot(aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_line(data = mtcars_wt, col = "blue")
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-13-1.png" width="900px" style="display: block; margin: auto;" /&gt;




```r
wt_seq %&gt;%
  mutate(mpg = predict(lm(mpg ~ wt + I(wt^2) + I(wt^3) + I(wt^4) + I(wt^5) + I(wt^6) + I(wt^7) + I(wt^8) + I(wt^9) + I(wt^10), data = mtcars), newdata = .)) -&gt; mtcars_wt

mtcars %&gt;% 
  ggplot(aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_line(data = mtcars_wt, col = "blue")
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-14-1.png" width="900px" style="display: block; margin: auto;" /&gt;



```r
mtcars %&gt;% 
  ggplot(aes(x = wt, y = mpg)) + 
  geom_point() -&gt; p

p + geom_smooth(method = lm, formula = y ~ x, se = F) + 
  labs(title = "Linear")
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-15-1.png" width="900px" style="display: block; margin: auto;" /&gt;


```r
p + geom_smooth(method = lm, formula = y ~ poly(x, 2), se = F, col = "purple") +
  labs(title )
```

&lt;img src="slides_51_files/figure-html/unnamed-chunk-16-1.png" width="900px" style="display: block; margin: auto;" /&gt;

  geom_smooth(method = lm, formula = y ~ poly(x, 10), se = F, col = "red")
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-lakeside-light",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
